ansible-role-ec2
================

An Ansible role, available via [Ansible Galaxy](https://galaxy.ansible.com), that creates an EC2 Ubuntu image.

You'll probably want to amend / override:

* `defaults/main.yml`

Installation
------------

We need `boto` to allow us to create EC2 instances

    # Install boto using pip
    pip install boto

    # Store our AWS credentials for use by boto
    echo -e "[Credentials]\naws_access_key_id = REDACTED\naws_secret_access_key = REDACTED" > ~/.boto

Preusming a `requirements.yml` as follows:

    # Install a role from GitHub
    - name: ansible-role-ec2
    src: https://github.com/jcdarwin/ansible-role-ec2

we can install the role locally:

    ansible-galaxy install -r requirements.yml -p ./roles


Requirements
------------

None.

Role Variables
--------------

Available variables are listed below, along with default values as found in `defaults/main.yml`:

    site:
      name: demo
      environment: development

    ansible_role_ec2:
      instance_type: m3.large
      security_group: "{{ site.environment }}-{{ site.name }}"
      # as sourced from https://cloud-images.ubuntu.com/locator/ec2/
      image: ami-bf86aedc # ubunutu 16.04 (ap-southeast-2)
      image_user: ubuntu
      region: ap-southeast-2
      #image: ami-ba4ea4da # amazon linux (us-west-2)
      #image_user: ec2-user
      #region: us-west-2
      keypair: aws
      private_key: ~/.ssh/aws.pem
      count: 1

Dependencies
------------

None.

Example Playbook
----------------

Our `hosts` file is populated during the ansible role execution, and will look something like:

    [local]
    127.0.0.1 ansible_python_interpreter=/usr/local/bin/python

    [demo]
    52.63.226.70 ansible_user=ubuntu ansible_private_key_file=~/.ssh/aws.pem

We include a playbook at `main.yml`.

Running the playbook:

    # Note that we're presuming our hosts file has been generated by our vagrant repo
    ansible all -m ping -i ansible/hosts -l all

    ansible-playbook -l all main.yml -i ansible/hosts --tags create

We should be able to then ssh in using our key pair -- note that the ip address is added to the
`./ansible/hosts` file by our ansible role:

    # The actual IP can be found in ansible/hosts
    ssh -i ~/.ssh/aws.pem ubuntu@52.63.226.70

Once we've finished with our EC2 instance, we can destroy it:

    ansible-playbook -l all main.yml -i ansible/hosts --tags destroy

License
-------

MIT

Author Information
------------------

http://github.com/jcdarwin
